{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_DATA_DIR = 'csv_self_data' # Дериктория с исходными данными (csv файлами, содержащими один столбец с заголовком \"vibration\")\n",
    "OUTPUT_DATASET_DIR = 'output_data_self_log' # Дериктория для результатов преобразования (изображения соответствующего размера и разрешения)\n",
    "\n",
    "SAMPLING_RATE = 9000 # Частота дискретизации      \n",
    "WINDOW_SIZE = 4096 # Размер фрейма для дробления исходных данных   \n",
    "STEP = 2048 # Шаг фрейма              \n",
    "\n",
    "NPERSEG = 1024 # Размер фрейма для создания спектрограммы            \n",
    "NOVERLAP = NPERSEG - 1 #коэф наложения фрейма   \n",
    "DPI = 100 # Разрешение изображения         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_files(file_list, subset_name):\n",
    "    for file_path in file_list:\n",
    "        label = os.path.basename(os.path.dirname(file_path))\n",
    "        dest_dir = os.path.join(OUTPUT_DATASET_DIR, subset_name, label)\n",
    "        os.makedirs(dest_dir, exist_ok=True)\n",
    "        shutil.copy(file_path, dest_dir)\n",
    "    print(f\"Скопировано {len(file_list)} файлов в '{subset_name}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_save_spectrogram_normalized(signal_data, fs, save_path):\n",
    "    \"\"\"\n",
    "    Создает спектрограмму из фрагмента сигнала, нормализует ее в диапазон [0, 1]\n",
    "    и сохраняет как изображение.\n",
    "    \"\"\"\n",
    "    frequencies, times, Zxx = signal.stft(\n",
    "        signal_data, \n",
    "        fs=fs, \n",
    "        nperseg=NPERSEG, \n",
    "        noverlap=NOVERLAP, \n",
    "        boundary=None,\n",
    "    )\n",
    "    \n",
    "    # Получаем модуль (амплитуду) спектрограммы\n",
    "    Zxx_abs = np.abs(Zxx)\n",
    "    \n",
    "    # Нормализация данных от 0 до 1\n",
    "    min_val = np.min(Zxx_abs)\n",
    "    max_val = np.max(Zxx_abs)\n",
    "    if max_val > min_val:\n",
    "        Zxx_normalized = (Zxx_abs - min_val) / (max_val - min_val)\n",
    "    else:\n",
    "        # Избегаем деления на ноль, если все значения одинаковы\n",
    "        Zxx_normalized = np.zeros_like(Zxx_abs)\n",
    "        \n",
    "    height, width = 513, 3073\n",
    "    dpi = DPI\n",
    "    fig_size = (width / dpi, height / dpi)\n",
    "    fig = plt.figure(figsize=fig_size)\n",
    "    ax = fig.add_axes([0, 0, 1, 1])\n",
    "    \n",
    "    # Используем нормализованные данные для отображения\n",
    "    ax.imshow(Zxx_normalized, cmap='gray', origin='lower', aspect='auto')\n",
    "    ax.axis('off')\n",
    "    plt.savefig(save_path, dpi=dpi)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Начинаем создание датасета...\n",
      "Очищена старая директория: output_data_self_log\n",
      "\n",
      "Обработка класса: 'normal'\n",
      "  Читаем файл: 10Hz_accelerometer.csv\n",
      "    -> Создано 42 изображений.\n",
      "  Читаем файл: 20Hz_accelerometer.csv\n",
      "    -> Создано 42 изображений.\n",
      "  Читаем файл: 30Hz_accelerometer.csv\n",
      "    -> Создано 42 изображений.\n",
      "  Читаем файл: 40Hz_accelerometer.csv\n",
      "    -> Создано 42 изображений.\n",
      "  Читаем файл: 50Hz_accelerometer.csv\n",
      "    -> Создано 42 изображений.\n",
      "\n",
      "Обработка класса: 'defect'\n",
      "  Читаем файл: 10Hz_accelerometer.csv\n",
      "    -> Создано 42 изображений.\n",
      "  Читаем файл: 20Hz_accelerometer.csv\n",
      "    -> Создано 42 изображений.\n",
      "  Читаем файл: 30Hz_accelerometer.csv\n",
      "    -> Создано 42 изображений.\n",
      "  Читаем файл: 40Hz_accelerometer.csv\n",
      "    -> Создано 42 изображений.\n",
      "  Читаем файл: 50Hz_accelerometer.csv\n",
      "    -> Создано 42 изображений.\n",
      "\n",
      "Всего создано изображений: 420\n",
      "Скопировано 336 файлов в 'train'\n",
      "Скопировано 84 файлов в 'validation'\n"
     ]
    }
   ],
   "source": [
    "def generate_dataset():\n",
    "    \"\"\"\n",
    "    Главная функция для обработки всех файлов и создания датасета.\n",
    "    \"\"\"\n",
    "    print(\"Начинаем создание датасета...\")\n",
    "\n",
    "    if os.path.exists(OUTPUT_DATASET_DIR):\n",
    "        shutil.rmtree(OUTPUT_DATASET_DIR)\n",
    "        print(f\"Очищена старая директория: {OUTPUT_DATASET_DIR}\")\n",
    "\n",
    "    all_file_chunks = []\n",
    "    temp_image_dir = os.path.join(OUTPUT_DATASET_DIR, 'temp_images')\n",
    "\n",
    "    for label in ['normal', 'defect']:\n",
    "        source_dir = os.path.join(SOURCE_DATA_DIR, label)\n",
    "        print(f\"\\nОбработка класса: '{label}'\")\n",
    "        for filename in os.listdir(source_dir):\n",
    "            if filename.endswith('.csv'):\n",
    "                file_path = os.path.join(source_dir, filename)\n",
    "                print(f\"  Читаем файл: {filename}\")\n",
    "                try:\n",
    "                    df = pd.read_csv(file_path)\n",
    "                    signal_data = df['vibration'].values\n",
    "                    chunk_count = 0\n",
    "                    \n",
    "                    for i in range(0, len(signal_data) - WINDOW_SIZE + 1, STEP):\n",
    "                        chunk = signal_data[i : i + WINDOW_SIZE]\n",
    "                        base_filename = os.path.splitext(filename)[0]\n",
    "                        image_filename = f\"{label}_{base_filename}_chunk_{chunk_count:04d}.png\"\n",
    "                        class_temp_dir = os.path.join(temp_image_dir, label)\n",
    "                        os.makedirs(class_temp_dir, exist_ok=True)\n",
    "                        save_path = os.path.join(class_temp_dir, image_filename)\n",
    "                        create_and_save_spectrogram_normalized(chunk, SAMPLING_RATE, save_path)\n",
    "                        all_file_chunks.append((save_path, label))\n",
    "                        chunk_count += 1\n",
    "                    print(f\"    -> Создано {chunk_count} изображений.\")\n",
    "                except Exception as e:\n",
    "                    print(f\"    ОШИБКА при обработке файла {filename}: {e}\")\n",
    "    print(f\"\\nВсего создано изображений: {len(all_file_chunks)}\")\n",
    "    paths, labels = zip(*all_file_chunks)\n",
    "    train_paths, val_paths, _, _ = train_test_split(paths, labels, test_size=0.2, random_state=42, stratify=labels)\n",
    "\n",
    "    copy_files(train_paths, 'train')\n",
    "    copy_files(val_paths, 'validation')\n",
    "    shutil.rmtree(temp_image_dir)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    generate_dataset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
