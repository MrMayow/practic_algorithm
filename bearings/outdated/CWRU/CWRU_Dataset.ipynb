{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prerequisites\n",
    "Understanding in\n",
    "- machine learning and deep learning\n",
    "- python syntax\n",
    "- python libraries: numpy, pandas, Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This notebook shows the study of the [CWRU Bearing Dataset](https://csegroups.case.edu/bearingdatacenter/home), which contains data of normal and fault bearings. Artificial defects of different diameters (0.007 ~ 0.028 Inches) are manufactured at different locations of the bearings: inner raceway(IR), outer raceway(OR) and ball(B) defects. \n",
    "\n",
    "Vibration data was recorded for motor loads of 0 to 3 hp (motor speed of 1797 to 1720 RPM) using accelerometers at the drive end (DE) and fan end (FE) and the data is stored as Matlab files. The sampling rate is 12 kHz and each Matlab file contains between ~120k to ~240k sample points. For more information please refer to the [website](https://csegroups.case.edu/bearingdatacenter/home).\n",
    "\n",
    "This study focuses on the classification of the drive end bearing defects using only the signal data at **DE**. It is a **multiclass classification** problem. The input is the vibration signal data at DE and the output is the type of defects:\n",
    "- 0 : Normal (N), \n",
    "- 1 : Fault at Ball (B),\n",
    "- 2 : Fault at Inner Raceway (IR), \n",
    "- 3 : Fault at Outer Raceway (OR), \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maybe/Рабочий стол/github/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Data science libraries\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Pytorch\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import Tensor\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch import optim\n",
    "from torch.nn.modules.loss import CrossEntropyLoss\n",
    "\n",
    "# Others\n",
    "from IPython.core.debugger import set_trace\n",
    "from pathlib import Path\n",
    "\n",
    "from helper import get_df_all, download\n",
    "from train_helper import get_dataloader, fit, validate \n",
    "import nn_model\n",
    "from data_urls import URLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir = Path('.')\n",
    "DATA_PATH = Path(\"./Data\")\n",
    "save_model_path = working_dir / 'Model'\n",
    "DE_path = DATA_PATH / '12k_DE'\n",
    "\n",
    "for path in [DATA_PATH, save_model_path]:\n",
    "    if not path.exists():\n",
    "        path.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Uncomment this to download the 12k_DE data if needed\n",
    "for name, url in URLS[\"DE_12k\"].items():\n",
    "    download(url, DE_path, name, suffix=\".mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#### HYPERPARAMETERS ####\n",
    "bs = 64\n",
    "lr = 0.001\n",
    "wd = 1e-5\n",
    "betas=(0.99, 0.999)\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "random_seed = 42\n",
    "print(device)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = get_df_all(DE_path, segment_length=500, normalize=True)\n",
    "features = df_all.columns[2:]\n",
    "target = 'label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>filename</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>490</th>\n",
       "      <th>491</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16920</th>\n",
       "      <td>1</td>\n",
       "      <td>Data/12k_DE/B007_0.mat</td>\n",
       "      <td>0.744324</td>\n",
       "      <td>0.035597</td>\n",
       "      <td>-0.732874</td>\n",
       "      <td>0.348374</td>\n",
       "      <td>0.545178</td>\n",
       "      <td>-0.895706</td>\n",
       "      <td>-0.869934</td>\n",
       "      <td>1.061787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044969</td>\n",
       "      <td>0.178514</td>\n",
       "      <td>0.253487</td>\n",
       "      <td>-0.031176</td>\n",
       "      <td>0.193743</td>\n",
       "      <td>0.221858</td>\n",
       "      <td>-0.236179</td>\n",
       "      <td>0.254658</td>\n",
       "      <td>0.438576</td>\n",
       "      <td>0.061369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4346</th>\n",
       "      <td>1</td>\n",
       "      <td>Data/12k_DE/B028_1.mat</td>\n",
       "      <td>0.486591</td>\n",
       "      <td>1.582707</td>\n",
       "      <td>0.143404</td>\n",
       "      <td>-1.996307</td>\n",
       "      <td>-0.829228</td>\n",
       "      <td>1.774347</td>\n",
       "      <td>1.044672</td>\n",
       "      <td>-1.405751</td>\n",
       "      <td>...</td>\n",
       "      <td>3.749680</td>\n",
       "      <td>1.292040</td>\n",
       "      <td>-3.318140</td>\n",
       "      <td>-1.191259</td>\n",
       "      <td>3.311875</td>\n",
       "      <td>1.207847</td>\n",
       "      <td>-3.015045</td>\n",
       "      <td>-1.247388</td>\n",
       "      <td>2.413012</td>\n",
       "      <td>1.253952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7454</th>\n",
       "      <td>3</td>\n",
       "      <td>Data/12k_DE/OR021@3_1.mat</td>\n",
       "      <td>-0.026308</td>\n",
       "      <td>0.196805</td>\n",
       "      <td>0.831245</td>\n",
       "      <td>0.623579</td>\n",
       "      <td>0.014310</td>\n",
       "      <td>-0.156743</td>\n",
       "      <td>-0.111548</td>\n",
       "      <td>-0.832946</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.351824</td>\n",
       "      <td>1.125868</td>\n",
       "      <td>1.052642</td>\n",
       "      <td>-0.083516</td>\n",
       "      <td>-0.036033</td>\n",
       "      <td>0.862138</td>\n",
       "      <td>0.780330</td>\n",
       "      <td>-0.220816</td>\n",
       "      <td>-0.582373</td>\n",
       "      <td>0.438796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15439</th>\n",
       "      <td>1</td>\n",
       "      <td>Data/12k_DE/B021_2.mat</td>\n",
       "      <td>-1.061048</td>\n",
       "      <td>0.741058</td>\n",
       "      <td>0.991140</td>\n",
       "      <td>-0.606354</td>\n",
       "      <td>-0.433570</td>\n",
       "      <td>0.469757</td>\n",
       "      <td>-0.203191</td>\n",
       "      <td>-0.613932</td>\n",
       "      <td>...</td>\n",
       "      <td>0.637994</td>\n",
       "      <td>-0.619995</td>\n",
       "      <td>-0.201676</td>\n",
       "      <td>0.086298</td>\n",
       "      <td>-0.101643</td>\n",
       "      <td>0.747120</td>\n",
       "      <td>0.393974</td>\n",
       "      <td>-0.712449</td>\n",
       "      <td>-1.085299</td>\n",
       "      <td>0.345473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5914</th>\n",
       "      <td>2</td>\n",
       "      <td>Data/12k_DE/IR028_1.mat</td>\n",
       "      <td>0.236060</td>\n",
       "      <td>-0.787117</td>\n",
       "      <td>-1.688834</td>\n",
       "      <td>-0.374154</td>\n",
       "      <td>1.346688</td>\n",
       "      <td>1.393329</td>\n",
       "      <td>0.833157</td>\n",
       "      <td>0.924008</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.618531</td>\n",
       "      <td>-0.862908</td>\n",
       "      <td>-0.014633</td>\n",
       "      <td>0.157840</td>\n",
       "      <td>-0.701609</td>\n",
       "      <td>-0.909062</td>\n",
       "      <td>-0.372696</td>\n",
       "      <td>0.013546</td>\n",
       "      <td>0.027150</td>\n",
       "      <td>0.260352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 502 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                   filename         0         1         2  \\\n",
       "16920      1     Data/12k_DE/B007_0.mat  0.744324  0.035597 -0.732874   \n",
       "4346       1     Data/12k_DE/B028_1.mat  0.486591  1.582707  0.143404   \n",
       "7454       3  Data/12k_DE/OR021@3_1.mat -0.026308  0.196805  0.831245   \n",
       "15439      1     Data/12k_DE/B021_2.mat -1.061048  0.741058  0.991140   \n",
       "5914       2    Data/12k_DE/IR028_1.mat  0.236060 -0.787117 -1.688834   \n",
       "\n",
       "              3         4         5         6         7  ...       490  \\\n",
       "16920  0.348374  0.545178 -0.895706 -0.869934  1.061787  ...  0.044969   \n",
       "4346  -1.996307 -0.829228  1.774347  1.044672 -1.405751  ...  3.749680   \n",
       "7454   0.623579  0.014310 -0.156743 -0.111548 -0.832946  ... -0.351824   \n",
       "15439 -0.606354 -0.433570  0.469757 -0.203191 -0.613932  ...  0.637994   \n",
       "5914  -0.374154  1.346688  1.393329  0.833157  0.924008  ... -0.618531   \n",
       "\n",
       "            491       492       493       494       495       496       497  \\\n",
       "16920  0.178514  0.253487 -0.031176  0.193743  0.221858 -0.236179  0.254658   \n",
       "4346   1.292040 -3.318140 -1.191259  3.311875  1.207847 -3.015045 -1.247388   \n",
       "7454   1.125868  1.052642 -0.083516 -0.036033  0.862138  0.780330 -0.220816   \n",
       "15439 -0.619995 -0.201676  0.086298 -0.101643  0.747120  0.393974 -0.712449   \n",
       "5914  -0.862908 -0.014633  0.157840 -0.701609 -0.909062 -0.372696  0.013546   \n",
       "\n",
       "            498       499  \n",
       "16920  0.438576  0.061369  \n",
       "4346   2.413012  1.253952  \n",
       "7454  -0.582373  0.438796  \n",
       "15439 -1.085299  0.345473  \n",
       "5914   0.027150  0.260352  \n",
       "\n",
       "[5 rows x 502 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17987, 502)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split the data into train and validation set\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(df_all[features], \n",
    "                                                      df_all[target], \n",
    "                                                      test_size=0.20, random_state=random_seed, shuffle=True\n",
    "                                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create DataLoader of train and validation set\n",
    "X_train = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "X_valid = torch.tensor(X_valid.values, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train.values, dtype=torch.long)\n",
    "y_valid = torch.tensor(y_valid.values, dtype=torch.long)\n",
    "\n",
    "train_ds = TensorDataset(X_train, y_train)\n",
    "valid_ds = TensorDataset(X_valid, y_valid)\n",
    "train_dl, valid_dl = get_dataloader(train_ds, valid_ds, bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with Adams Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Instantiate model, optimizer and loss function\n",
    "model = nn_model.CNN_1D_2L(len(features))\n",
    "model.to(device)\n",
    "opt = optim.Adam(model.parameters(), lr=lr, betas=betas, weight_decay=wd)\n",
    "loss_func = CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH \t Train Loss \t Val Loss \t Train Acc \t Val Acc \t\n",
      "0 \t 0.01264 \t 0.37007 \t 0.00000 \t0.88049 \t\n",
      "1 \t 0.00329 \t 0.22787 \t 0.00000 \t0.91245 \t\n",
      "2 \t 0.00148 \t 0.27648 \t 0.00000 \t0.89550 \t\n",
      "3 \t 0.00115 \t 0.11189 \t 0.00000 \t0.96220 \t\n",
      "4 \t 0.00085 \t 0.09620 \t 0.00000 \t0.96609 \t\n",
      "5 \t 0.00061 \t 0.08284 \t 0.00000 \t0.97193 \t\n",
      "6 \t 0.00067 \t 0.17547 \t 0.00000 \t0.93663 \t\n",
      "7 \t 0.00054 \t 0.09470 \t 0.00000 \t0.97082 \t\n",
      "8 \t 0.00045 \t 0.07605 \t 0.00000 \t0.97610 \t\n",
      "9 \t 0.00041 \t 0.06929 \t 0.00000 \t0.97387 \t\n",
      "10 \t 0.00039 \t 0.05818 \t 0.00000 \t0.97804 \t\n",
      "11 \t 0.00043 \t 0.04972 \t 0.00000 \t0.98166 \t\n",
      "12 \t 0.00040 \t 0.04208 \t 0.00000 \t0.98249 \t\n",
      "13 \t 0.00032 \t 0.05615 \t 0.00000 \t0.98277 \t\n",
      "14 \t 0.00029 \t 0.02324 \t 0.00000 \t0.99444 \t\n",
      "15 \t 0.00018 \t 0.04442 \t 0.00000 \t0.98277 \t\n",
      "16 \t 0.00030 \t 0.03703 \t 0.00000 \t0.98805 \t\n",
      "17 \t 0.00029 \t 0.08931 \t 0.00000 \t0.96998 \t\n",
      "18 \t 0.00046 \t 0.02955 \t 0.00000 \t0.99055 \t\n",
      "19 \t 0.00054 \t 0.08679 \t 0.00000 \t0.97499 \t\n",
      "CPU times: user 16.8 s, sys: 165 ms, total: 16.9 s\n",
      "Wall time: 17.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Train\n",
    "epochs = 20\n",
    "model, metrics = fit(epochs, model, loss_func, opt, train_dl, valid_dl, train_metric=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH \t Train Loss \t Val Loss \t Train Acc \t Val Acc \t\n",
      "0 \t 0.00001 \t 0.17479 \t 0.00000 \t0.97437 \t\n",
      "1 \t 0.00006 \t 0.13076 \t 0.00000 \t0.97994 \t\n",
      "2 \t 0.00004 \t 0.11195 \t 0.00000 \t0.98440 \t\n",
      "CPU times: user 2.13 s, sys: 14.9 ms, total: 2.15 s\n",
      "Wall time: 2.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Train\n",
    "epochs = 3\n",
    "model, metrics = fit(epochs, model, loss_func, opt, train_dl, valid_dl, train_metric=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), save_model_path / 'model_12k.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = nn_model.CNN_1D_2L(len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4961/1042841811.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model2.load_state_dict(torch.load(save_model_path / 'model_12k_1000.pth'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CNN_1D_2L(\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv1d(1, 64, kernel_size=(9,), stride=(1,), padding=(4,))\n",
       "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv1d(64, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
       "  )\n",
       "  (linear1): Linear(in_features=32000, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.load_state_dict(torch.load(save_model_path / 'model_12k.pth'))\n",
    "model2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.06863823064439475, np.float64(0.9860724233983287), (array([0, 3, 2, ..., 2, 1, 1], shape=(1795,)), array([0, 3, 2, ..., 2, 1, 1], shape=(1795,))))\n",
      "CPU times: user 58.6 ms, sys: 2.94 ms, total: 61.5 ms\n",
      "Wall time: 60.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(validate(model, valid_dl, loss_func))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
