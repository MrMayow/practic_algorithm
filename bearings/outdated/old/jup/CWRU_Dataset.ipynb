{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prerequisites\n",
    "Understanding in\n",
    "- machine learning and deep learning\n",
    "- python syntax\n",
    "- python libraries: numpy, pandas, Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This notebook shows the study of the [CWRU Bearing Dataset](https://csegroups.case.edu/bearingdatacenter/home), which contains data of normal and fault bearings. Artificial defects of different diameters (0.007 ~ 0.028 Inches) are manufactured at different locations of the bearings: inner raceway(IR), outer raceway(OR) and ball(B) defects. \n",
    "\n",
    "Vibration data was recorded for motor loads of 0 to 3 hp (motor speed of 1797 to 1720 RPM) using accelerometers at the drive end (DE) and fan end (FE) and the data is stored as Matlab files. The sampling rate is 12 kHz and each Matlab file contains between ~120k to ~240k sample points. For more information please refer to the [website](https://csegroups.case.edu/bearingdatacenter/home).\n",
    "\n",
    "This study focuses on the classification of the drive end bearing defects using only the signal data at **DE**. It is a **multiclass classification** problem. The input is the vibration signal data at DE and the output is the type of defects:\n",
    "- 0 : Normal (N), \n",
    "- 1 : Fault at Ball (B),\n",
    "- 2 : Fault at Inner Raceway (IR), \n",
    "- 3 : Fault at Outer Raceway (OR), \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\scree\\Desktop\\bearings\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Data science libraries\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Pytorch\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import Tensor\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch import optim\n",
    "from torch.nn.modules.loss import CrossEntropyLoss\n",
    "\n",
    "# Others\n",
    "from IPython.core.debugger import set_trace\n",
    "from pathlib import Path\n",
    "\n",
    "from helper import get_df_all, download\n",
    "from train_helper import get_dataloader, fit, validate \n",
    "import nn_model\n",
    "from data_urls import URLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir = Path('.')\n",
    "DATA_PATH = Path(\"./Data\")\n",
    "save_model_path = working_dir / 'Model'\n",
    "DE_path = DATA_PATH / '12k_DE'\n",
    "\n",
    "for path in [DATA_PATH, save_model_path]:\n",
    "    if not path.exists():\n",
    "        path.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Uncomment this to download the 12k_DE data if needed\n",
    "# for name, url in URLS[\"DE_12k\"].items():\n",
    "#     download(url, DE_path, name, suffix=\".mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "#### HYPERPARAMETERS ####\n",
    "bs = 64\n",
    "lr = 0.001\n",
    "wd = 1e-5\n",
    "betas=(0.99, 0.999)\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)\n",
    "random_seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         filename                                            DE_time label\n",
      "0      B007_0.mat  [[-0.0027613972055888225], [-0.096324031936127...     B\n",
      "1      B007_1.mat  [[-0.07212119760479042], [0.30310395209580837]...     B\n",
      "2      B007_2.mat  [[-0.3144744111776447], [0.12198878243512974],...     B\n",
      "3      B007_3.mat  [[0.09031393213572854], [0.22497265469061875],...     B\n",
      "4      B014_0.mat  [[-0.46781317365269465], [0.1790035129740519],...     B\n",
      "..            ...                                                ...   ...\n",
      "59  OR021@3_3.mat  [[0.08868958083832335], [0.06854762475049901],...    OR\n",
      "60  OR021@6_0.mat  [[0.10436457085828342], [0.017461776447105788]...    OR\n",
      "61  OR021@6_1.mat  [[-0.025989620758483035], [-0.0272078842315369...    OR\n",
      "62  OR021@6_2.mat  [[-0.08771497005988023], [-0.00203043912175648...    OR\n",
      "63  OR021@6_3.mat  [[-0.27613972055888225], [0.0625375249500998],...    OR\n",
      "\n",
      "[64 rows x 3 columns]\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "      label       filename         0         1         2         3         4  \\\n",
      "0         B     B007_0.mat -0.110834 -0.785589  0.729095  1.764657 -0.511470   \n",
      "1         B     B007_0.mat  1.434308 -0.601672 -0.789104  1.772857  1.501081   \n",
      "2         B     B007_0.mat  0.372975 -0.101463  0.262858  0.641237  0.312059   \n",
      "3         B     B007_0.mat -0.805504 -0.818390  0.565092  0.237086 -0.718817   \n",
      "4         B     B007_0.mat  0.006311  0.515891 -0.906249 -1.289313  0.249972   \n",
      "...     ...            ...       ...       ...       ...       ...       ...   \n",
      "17982    OR  OR021@6_3.mat  0.177441  0.119325 -0.732800 -0.361584  0.326363   \n",
      "17983    OR  OR021@6_3.mat  0.005273 -0.001992  0.053945 -0.003445 -0.091345   \n",
      "17984    OR  OR021@6_3.mat -0.155999 -0.076816 -0.169075 -0.145829  0.136760   \n",
      "17985    OR  OR021@6_3.mat -5.122736  0.965639  3.917931  0.080097  0.319825   \n",
      "17986    OR  OR021@6_3.mat -0.047758 -1.568217  0.175988  0.812358 -0.750961   \n",
      "\n",
      "              5         6         7  ...       490       491       492  \\\n",
      "0     -0.999965  1.405022  1.154332  ... -0.545442 -0.621586  0.652951   \n",
      "1     -0.772703 -0.329895  1.253905  ... -0.828933 -0.423611  0.404604   \n",
      "2      0.101198  0.630694  0.483091  ... -0.641501  0.719724  0.590864   \n",
      "3      0.143370  0.635379 -0.602843  ...  0.668180  0.158599 -0.701245   \n",
      "4     -0.292409 -1.500174  0.002796  ... -0.919135 -0.030004  1.414393   \n",
      "...         ...       ...       ...  ...       ...       ...       ...   \n",
      "17982 -0.231550 -0.506874  0.616943  ... -0.273684 -0.105874  0.368497   \n",
      "17983 -0.112412 -0.214115 -0.230097  ... -0.110959 -0.211936 -0.188689   \n",
      "17984  0.189064  0.125863  0.135307  ...  1.281645 -0.920951 -3.147519   \n",
      "17985  0.714288  0.856672  3.506034  ... -2.176982  1.801056  2.155564   \n",
      "17986 -1.265288  0.062662  0.149836  ...  0.125863 -0.018700 -0.134206   \n",
      "\n",
      "            493       494       495       496       497       498       499  \n",
      "0      0.367117 -0.806675 -0.288895  0.982128 -0.457583 -2.002726  0.041454  \n",
      "1     -0.109663 -0.452898  0.112913  0.753696  0.128142 -0.451726  0.289802  \n",
      "2     -1.436915 -0.934363  1.304277  0.611950 -0.798475  0.466691  1.059444  \n",
      "3      0.261687  0.914184  0.175000  0.221858  1.148474  1.014929 -0.314666  \n",
      "4      0.364774 -0.553642  0.792354  1.157846 -0.525527 -0.388468  0.416318  \n",
      "...         ...       ...       ...       ...       ...       ...       ...  \n",
      "17982  0.332175  0.165818  0.226840  0.393923  0.299485  0.011084 -0.006351  \n",
      "17983 -0.012162  0.004546 -0.243173 -0.055023  0.306023  0.170177 -0.108780  \n",
      "17984  0.152015  3.246691 -1.916187 -3.831108  2.743262  3.317883 -2.793738  \n",
      "17985 -1.606719 -1.059703  2.642285  0.747704 -2.433419  0.194150  2.235473  \n",
      "17986  0.074285  0.016169 -0.216295 -0.206124 -0.079722 -0.025965 -0.036861  \n",
      "\n",
      "[17987 rows x 502 columns]\n"
     ]
    }
   ],
   "source": [
    "df_all = get_df_all(DE_path, segment_length=500, normalize=False)\n",
    "features = df_all.columns[2:]\n",
    "target = 'label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>filename</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>490</th>\n",
       "      <th>491</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2990</th>\n",
       "      <td>1</td>\n",
       "      <td>B028_0.mat</td>\n",
       "      <td>0.085747</td>\n",
       "      <td>0.595471</td>\n",
       "      <td>-0.674725</td>\n",
       "      <td>-0.277838</td>\n",
       "      <td>1.004504</td>\n",
       "      <td>0.133938</td>\n",
       "      <td>-1.419917</td>\n",
       "      <td>-0.418492</td>\n",
       "      <td>...</td>\n",
       "      <td>1.035456</td>\n",
       "      <td>0.532784</td>\n",
       "      <td>-1.141743</td>\n",
       "      <td>-0.832226</td>\n",
       "      <td>1.065624</td>\n",
       "      <td>1.098143</td>\n",
       "      <td>-0.838887</td>\n",
       "      <td>-1.269860</td>\n",
       "      <td>0.340805</td>\n",
       "      <td>1.025661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11922</th>\n",
       "      <td>3</td>\n",
       "      <td>OR007@12_3.mat</td>\n",
       "      <td>0.098072</td>\n",
       "      <td>0.224257</td>\n",
       "      <td>0.185577</td>\n",
       "      <td>0.297812</td>\n",
       "      <td>0.393560</td>\n",
       "      <td>-0.038893</td>\n",
       "      <td>-0.263996</td>\n",
       "      <td>0.196357</td>\n",
       "      <td>...</td>\n",
       "      <td>0.490577</td>\n",
       "      <td>1.512737</td>\n",
       "      <td>-0.830243</td>\n",
       "      <td>-1.074369</td>\n",
       "      <td>1.040337</td>\n",
       "      <td>0.462676</td>\n",
       "      <td>-0.788393</td>\n",
       "      <td>0.232500</td>\n",
       "      <td>0.537500</td>\n",
       "      <td>-0.513830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6383</th>\n",
       "      <td>2</td>\n",
       "      <td>IR021_2.mat</td>\n",
       "      <td>0.021230</td>\n",
       "      <td>0.128390</td>\n",
       "      <td>0.211460</td>\n",
       "      <td>0.043659</td>\n",
       "      <td>-0.158200</td>\n",
       "      <td>0.108454</td>\n",
       "      <td>-0.283636</td>\n",
       "      <td>-0.341784</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.197243</td>\n",
       "      <td>-0.463066</td>\n",
       "      <td>0.245519</td>\n",
       "      <td>0.658375</td>\n",
       "      <td>0.272932</td>\n",
       "      <td>-0.018643</td>\n",
       "      <td>0.181555</td>\n",
       "      <td>0.318620</td>\n",
       "      <td>-0.195582</td>\n",
       "      <td>-0.451436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7053</th>\n",
       "      <td>2</td>\n",
       "      <td>IR028_1.mat</td>\n",
       "      <td>1.340372</td>\n",
       "      <td>-0.337230</td>\n",
       "      <td>-1.523649</td>\n",
       "      <td>0.114115</td>\n",
       "      <td>2.380554</td>\n",
       "      <td>1.562401</td>\n",
       "      <td>-0.476180</td>\n",
       "      <td>0.540196</td>\n",
       "      <td>...</td>\n",
       "      <td>0.645137</td>\n",
       "      <td>0.122860</td>\n",
       "      <td>-0.694807</td>\n",
       "      <td>-0.482982</td>\n",
       "      <td>0.174845</td>\n",
       "      <td>0.515904</td>\n",
       "      <td>-0.244435</td>\n",
       "      <td>-0.839587</td>\n",
       "      <td>0.176788</td>\n",
       "      <td>1.101826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4686</th>\n",
       "      <td>2</td>\n",
       "      <td>IR007_3.mat</td>\n",
       "      <td>0.031574</td>\n",
       "      <td>-0.787928</td>\n",
       "      <td>1.640016</td>\n",
       "      <td>2.365757</td>\n",
       "      <td>-0.495249</td>\n",
       "      <td>-0.156466</td>\n",
       "      <td>0.290065</td>\n",
       "      <td>-2.505671</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.242975</td>\n",
       "      <td>-1.351012</td>\n",
       "      <td>1.778844</td>\n",
       "      <td>1.899024</td>\n",
       "      <td>-1.820853</td>\n",
       "      <td>-1.284706</td>\n",
       "      <td>1.305377</td>\n",
       "      <td>0.165741</td>\n",
       "      <td>-0.710226</td>\n",
       "      <td>0.326326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12003</th>\n",
       "      <td>3</td>\n",
       "      <td>OR007@12_3.mat</td>\n",
       "      <td>-0.071231</td>\n",
       "      <td>-0.044599</td>\n",
       "      <td>-0.114984</td>\n",
       "      <td>-0.047770</td>\n",
       "      <td>-0.042697</td>\n",
       "      <td>-0.128300</td>\n",
       "      <td>-0.392718</td>\n",
       "      <td>-0.302676</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.436470</td>\n",
       "      <td>0.209673</td>\n",
       "      <td>0.285130</td>\n",
       "      <td>-0.826438</td>\n",
       "      <td>-0.510025</td>\n",
       "      <td>0.211575</td>\n",
       "      <td>-0.231657</td>\n",
       "      <td>-0.920918</td>\n",
       "      <td>-0.222780</td>\n",
       "      <td>0.397365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5913</th>\n",
       "      <td>2</td>\n",
       "      <td>IR021_0.mat</td>\n",
       "      <td>0.113020</td>\n",
       "      <td>-0.568197</td>\n",
       "      <td>-0.303752</td>\n",
       "      <td>0.467933</td>\n",
       "      <td>0.474892</td>\n",
       "      <td>0.181837</td>\n",
       "      <td>0.424632</td>\n",
       "      <td>0.497316</td>\n",
       "      <td>...</td>\n",
       "      <td>0.279265</td>\n",
       "      <td>-1.635256</td>\n",
       "      <td>-1.916712</td>\n",
       "      <td>0.560721</td>\n",
       "      <td>1.367974</td>\n",
       "      <td>-1.019764</td>\n",
       "      <td>-1.102499</td>\n",
       "      <td>1.760002</td>\n",
       "      <td>1.666441</td>\n",
       "      <td>-1.141934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7819</th>\n",
       "      <td>0</td>\n",
       "      <td>Normal_0.mat</td>\n",
       "      <td>-1.966550</td>\n",
       "      <td>-1.160067</td>\n",
       "      <td>-0.310533</td>\n",
       "      <td>0.605012</td>\n",
       "      <td>1.147451</td>\n",
       "      <td>1.709980</td>\n",
       "      <td>1.827652</td>\n",
       "      <td>1.135971</td>\n",
       "      <td>...</td>\n",
       "      <td>0.315137</td>\n",
       "      <td>0.610752</td>\n",
       "      <td>0.536131</td>\n",
       "      <td>0.140064</td>\n",
       "      <td>-0.626238</td>\n",
       "      <td>-1.197378</td>\n",
       "      <td>-1.246168</td>\n",
       "      <td>-1.142847</td>\n",
       "      <td>-0.987864</td>\n",
       "      <td>-1.025175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11987</th>\n",
       "      <td>3</td>\n",
       "      <td>OR007@12_3.mat</td>\n",
       "      <td>0.321273</td>\n",
       "      <td>-0.340722</td>\n",
       "      <td>-0.314090</td>\n",
       "      <td>0.538134</td>\n",
       "      <td>0.978829</td>\n",
       "      <td>0.229329</td>\n",
       "      <td>-0.390181</td>\n",
       "      <td>0.105681</td>\n",
       "      <td>...</td>\n",
       "      <td>0.700462</td>\n",
       "      <td>-0.739567</td>\n",
       "      <td>0.053051</td>\n",
       "      <td>1.033362</td>\n",
       "      <td>-0.568996</td>\n",
       "      <td>-1.215138</td>\n",
       "      <td>0.607884</td>\n",
       "      <td>0.702364</td>\n",
       "      <td>-0.797270</td>\n",
       "      <td>-0.147323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4775</th>\n",
       "      <td>2</td>\n",
       "      <td>IR007_3.mat</td>\n",
       "      <td>-0.561037</td>\n",
       "      <td>0.517992</td>\n",
       "      <td>0.571348</td>\n",
       "      <td>-0.110880</td>\n",
       "      <td>0.372947</td>\n",
       "      <td>0.962450</td>\n",
       "      <td>0.334096</td>\n",
       "      <td>-0.450181</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.802433</td>\n",
       "      <td>0.632992</td>\n",
       "      <td>1.436953</td>\n",
       "      <td>-0.116061</td>\n",
       "      <td>-0.784820</td>\n",
       "      <td>0.148128</td>\n",
       "      <td>-0.005205</td>\n",
       "      <td>-0.578131</td>\n",
       "      <td>-0.181331</td>\n",
       "      <td>-0.288042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 502 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label        filename         0         1         2         3  \\\n",
       "2990       1      B028_0.mat  0.085747  0.595471 -0.674725 -0.277838   \n",
       "11922      3  OR007@12_3.mat  0.098072  0.224257  0.185577  0.297812   \n",
       "6383       2     IR021_2.mat  0.021230  0.128390  0.211460  0.043659   \n",
       "7053       2     IR028_1.mat  1.340372 -0.337230 -1.523649  0.114115   \n",
       "4686       2     IR007_3.mat  0.031574 -0.787928  1.640016  2.365757   \n",
       "12003      3  OR007@12_3.mat -0.071231 -0.044599 -0.114984 -0.047770   \n",
       "5913       2     IR021_0.mat  0.113020 -0.568197 -0.303752  0.467933   \n",
       "7819       0    Normal_0.mat -1.966550 -1.160067 -0.310533  0.605012   \n",
       "11987      3  OR007@12_3.mat  0.321273 -0.340722 -0.314090  0.538134   \n",
       "4775       2     IR007_3.mat -0.561037  0.517992  0.571348 -0.110880   \n",
       "\n",
       "              4         5         6         7  ...       490       491  \\\n",
       "2990   1.004504  0.133938 -1.419917 -0.418492  ...  1.035456  0.532784   \n",
       "11922  0.393560 -0.038893 -0.263996  0.196357  ...  0.490577  1.512737   \n",
       "6383  -0.158200  0.108454 -0.283636 -0.341784  ... -0.197243 -0.463066   \n",
       "7053   2.380554  1.562401 -0.476180  0.540196  ...  0.645137  0.122860   \n",
       "4686  -0.495249 -0.156466  0.290065 -2.505671  ... -0.242975 -1.351012   \n",
       "12003 -0.042697 -0.128300 -0.392718 -0.302676  ... -0.436470  0.209673   \n",
       "5913   0.474892  0.181837  0.424632  0.497316  ...  0.279265 -1.635256   \n",
       "7819   1.147451  1.709980  1.827652  1.135971  ...  0.315137  0.610752   \n",
       "11987  0.978829  0.229329 -0.390181  0.105681  ...  0.700462 -0.739567   \n",
       "4775   0.372947  0.962450  0.334096 -0.450181  ... -0.802433  0.632992   \n",
       "\n",
       "            492       493       494       495       496       497       498  \\\n",
       "2990  -1.141743 -0.832226  1.065624  1.098143 -0.838887 -1.269860  0.340805   \n",
       "11922 -0.830243 -1.074369  1.040337  0.462676 -0.788393  0.232500  0.537500   \n",
       "6383   0.245519  0.658375  0.272932 -0.018643  0.181555  0.318620 -0.195582   \n",
       "7053  -0.694807 -0.482982  0.174845  0.515904 -0.244435 -0.839587  0.176788   \n",
       "4686   1.778844  1.899024 -1.820853 -1.284706  1.305377  0.165741 -0.710226   \n",
       "12003  0.285130 -0.826438 -0.510025  0.211575 -0.231657 -0.920918 -0.222780   \n",
       "5913  -1.916712  0.560721  1.367974 -1.019764 -1.102499  1.760002  1.666441   \n",
       "7819   0.536131  0.140064 -0.626238 -1.197378 -1.246168 -1.142847 -0.987864   \n",
       "11987  0.053051  1.033362 -0.568996 -1.215138  0.607884  0.702364 -0.797270   \n",
       "4775   1.436953 -0.116061 -0.784820  0.148128 -0.005205 -0.578131 -0.181331   \n",
       "\n",
       "            499  \n",
       "2990   1.025661  \n",
       "11922 -0.513830  \n",
       "6383  -0.451436  \n",
       "7053   1.101826  \n",
       "4686   0.326326  \n",
       "12003  0.397365  \n",
       "5913  -1.141934  \n",
       "7819  -1.025175  \n",
       "11987 -0.147323  \n",
       "4775  -0.288042  \n",
       "\n",
       "[10 rows x 502 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17987, 502)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split the data into train and validation set\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(df_all[features], \n",
    "                                                      df_all[target], \n",
    "                                                      test_size=0.20, random_state=random_seed, shuffle=True\n",
    "                                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create DataLoader of train and validation set\n",
    "X_train = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "X_valid = torch.tensor(X_valid.values, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train.values, dtype=torch.long)\n",
    "y_valid = torch.tensor(y_valid.values, dtype=torch.long)\n",
    "\n",
    "train_ds = TensorDataset(X_train, y_train)\n",
    "valid_ds = TensorDataset(X_valid, y_valid)\n",
    "train_dl, valid_dl = get_dataloader(train_ds, valid_ds, bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with Adams Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Instantiate model, optimizer and loss function\n",
    "model = nn_model.CNN_1D_2L(len(features))\n",
    "model.to(device)\n",
    "opt = optim.Adam(model.parameters(), lr=lr, betas=betas, weight_decay=wd)\n",
    "loss_func = CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH \t Train Loss \t Val Loss \t Train Acc \t Val Acc \t\n",
      "CPU times: total: 281 ms\n",
      "Wall time: 295 ms\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtime\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m## Train\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mepochs = 20\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mmodel, metrics = fit(epochs, model, loss_func, opt, train_dl, valid_dl, train_metric=False)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\scree\\Desktop\\bearings\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:2565\u001b[39m, in \u001b[36mInteractiveShell.run_cell_magic\u001b[39m\u001b[34m(self, magic_name, line, cell)\u001b[39m\n\u001b[32m   2563\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.builtin_trap:\n\u001b[32m   2564\u001b[39m     args = (magic_arg_s, cell)\n\u001b[32m-> \u001b[39m\u001b[32m2565\u001b[39m     result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2567\u001b[39m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[32m   2568\u001b[39m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[32m   2569\u001b[39m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[32m   2570\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\scree\\Desktop\\bearings\\.venv\\Lib\\site-packages\\IPython\\core\\magics\\execution.py:1470\u001b[39m, in \u001b[36mExecutionMagics.time\u001b[39m\u001b[34m(self, line, cell, local_ns)\u001b[39m\n\u001b[32m   1468\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m interrupt_occured:\n\u001b[32m   1469\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exit_on_interrupt \u001b[38;5;129;01mand\u001b[39;00m captured_exception:\n\u001b[32m-> \u001b[39m\u001b[32m1470\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m captured_exception\n\u001b[32m   1471\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m   1472\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\scree\\Desktop\\bearings\\.venv\\Lib\\site-packages\\IPython\\core\\magics\\execution.py:1434\u001b[39m, in \u001b[36mExecutionMagics.time\u001b[39m\u001b[34m(self, line, cell, local_ns)\u001b[39m\n\u001b[32m   1432\u001b[39m st = clock2()\n\u001b[32m   1433\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1434\u001b[39m     \u001b[43mexec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_ns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1435\u001b[39m     out = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1436\u001b[39m     \u001b[38;5;66;03m# multi-line %%time case\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<timed exec>:3\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\scree\\Desktop\\bearings\\jup\\train_helper.py:129\u001b[39m, in \u001b[36mfit\u001b[39m\u001b[34m(epochs, model, loss_func, opt, train_dl, valid_dl, one_cycle, train_metric)\u001b[39m\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m xb, yb \u001b[38;5;129;01min\u001b[39;00m train_dl:\n\u001b[32m    128\u001b[39m     xb, yb = xb.to(device), yb.to(device)\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m     loss, batch_size, pred = \u001b[43mloss_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    130\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m train_metric == \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m    131\u001b[39m         train_loss += loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\scree\\Desktop\\bearings\\jup\\train_helper.py:65\u001b[39m, in \u001b[36mloss_batch\u001b[39m\u001b[34m(model, loss_func, xb, yb, opt)\u001b[39m\n\u001b[32m     62\u001b[39m pred = torch.argmax(out, dim=\u001b[32m1\u001b[39m).cpu().numpy()\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m opt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     66\u001b[39m     opt.step()\n\u001b[32m     67\u001b[39m     opt.zero_grad()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\scree\\Desktop\\bearings\\.venv\\Lib\\site-packages\\torch\\_tensor.py:581\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    571\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    572\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    573\u001b[39m         Tensor.backward,\n\u001b[32m    574\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    579\u001b[39m         inputs=inputs,\n\u001b[32m    580\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m581\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    582\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    583\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\scree\\Desktop\\bearings\\.venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    342\u001b[39m     retain_graph = create_graph\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\scree\\Desktop\\bearings\\.venv\\Lib\\site-packages\\torch\\autograd\\graph.py:825\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    823\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    824\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m825\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    826\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    827\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    828\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    829\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Train\n",
    "epochs = 20\n",
    "model, metrics = fit(epochs, model, loss_func, opt, train_dl, valid_dl, train_metric=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH \t Train Loss \t Val Loss \t Train Acc \t Val Acc \t\n",
      "0 \t 0.00022 \t 0.24229 \t 0.00000 \t0.93274 \t\n",
      "1 \t 0.00020 \t 0.05039 \t 0.00000 \t0.98193 \t\n",
      "2 \t 0.00029 \t 0.17963 \t 0.00000 \t0.94997 \t\n",
      "3 \t 0.00029 \t 0.07733 \t 0.00000 \t0.97721 \t\n",
      "4 \t 0.00028 \t 0.04317 \t 0.00000 \t0.98555 \t\n",
      "5 \t 0.00017 \t 0.03448 \t 0.00000 \t0.99138 \t\n",
      "6 \t 0.00018 \t 0.07745 \t 0.00000 \t0.97665 \t\n",
      "7 \t 0.00014 \t 0.06705 \t 0.00000 \t0.98054 \t\n",
      "8 \t 0.00033 \t 0.06601 \t 0.00000 \t0.97860 \t\n",
      "9 \t 0.00022 \t 0.04243 \t 0.00000 \t0.98777 \t\n",
      "10 \t 0.00020 \t 0.08321 \t 0.00000 \t0.97193 \t\n",
      "11 \t 0.00018 \t 0.04951 \t 0.00000 \t0.98888 \t\n",
      "12 \t 0.00019 \t 0.05189 \t 0.00000 \t0.98360 \t\n",
      "13 \t 0.00014 \t 0.06283 \t 0.00000 \t0.97860 \t\n",
      "14 \t 0.00022 \t 0.02842 \t 0.00000 \t0.98999 \t\n",
      "15 \t 0.00017 \t 0.04112 \t 0.00000 \t0.98638 \t\n",
      "16 \t 0.00020 \t 0.02733 \t 0.00000 \t0.99055 \t\n",
      "17 \t 0.00020 \t 0.08156 \t 0.00000 \t0.97387 \t\n",
      "18 \t 0.00017 \t 0.03271 \t 0.00000 \t0.98944 \t\n",
      "19 \t 0.00016 \t 0.06353 \t 0.00000 \t0.98638 \t\n",
      "CPU times: total: 9.77 s\n",
      "Wall time: 10.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Train\n",
    "epochs = 20\n",
    "model, metrics = fit(epochs, model, loss_func, opt, train_dl, valid_dl, train_metric=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), save_model_path / 'model_2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = nn_model.CNN_1D_2L(len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scree\\AppData\\Local\\Temp\\ipykernel_34356\\214197978.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model2.load_state_dict(torch.load(save_model_path / 'model_2.pth'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CNN_1D_2L(\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv1d(1, 64, kernel_size=(9,), stride=(1,), padding=(4,))\n",
       "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv1d(64, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
       "  )\n",
       "  (linear1): Linear(in_features=16000, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.load_state_dict(torch.load(save_model_path / 'model_2.pth'))\n",
    "model2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.06352972865203424, np.float64(0.9863813229571985), (array([2, 0, 1, ..., 3, 1, 3], shape=(3598,)), array([2, 0, 1, ..., 3, 1, 3], shape=(3598,))))\n",
      "CPU times: total: 156 ms\n",
      "Wall time: 151 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(validate(model, valid_dl, loss_func))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
